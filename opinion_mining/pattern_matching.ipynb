{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pattern Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "from nltk import pos_tag, ngrams\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "stars_data = pd.read_csv(\"data/train_stars.csv\", names=[\"Processed Review Text\", \"Review Text\", \"Stars\"])\n",
    "pol_data = pd.read_csv(\"data/train_polarity.csv\", names=[\"Processed Review Text\", \"Review Text\", \"Polarity\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pattern Recognition using POS Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize reviews for POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [i, was, not, able, to, complete, the, peer, g...\n",
       "1    [language, was, understandable, enough, but, a...\n",
       "2    [a, thorough, yet, concise, introduction, to, ...\n",
       "3    [poor, labs, labs, do, not, teach, match, lect...\n",
       "4                         [where, is, my, certificate]\n",
       "Name: Review Text, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize all reviews for pre-processing purposes\n",
    "pol_data[\"Review Text\"] = pol_data[\"Review Text\"].apply(word_tokenize)\n",
    "pol_data[\"Review Text\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tag Reviews with POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [(i, NN), (was, VBD), (not, RB), (able, JJ), (...\n",
       "1    [(language, NN), (was, VBD), (understandable, ...\n",
       "2    [(a, DT), (thorough, JJ), (yet, RB), (concise,...\n",
       "3    [(poor, JJ), (labs, NNS), (labs, NNS), (do, VB...\n",
       "4    [(where, WRB), (is, VBZ), (my, PRP$), (certifi...\n",
       "Name: Tagged Text, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pol_data[\"Tagged Text\"] = pol_data[\"Review Text\"].apply(pos_tag)\n",
    "pol_data[\"Tagged Text\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [NN, VBD, RB, JJ, TO, VB, DT, NN, VBD, NN, DT,...\n",
       "1    [NN, VBD, JJ, RB, CC, VBG, NNS, MD, VB, JJ, IN...\n",
       "2    [DT, JJ, RB, JJ, NN, TO, DT, NN, CC, TO, DT, I...\n",
       "3    [JJ, NNS, NNS, VBP, RB, VB, NN, NNS, JJ, NN, T...\n",
       "4                                 [WRB, VBZ, PRP$, NN]\n",
       "Name: POS Tags, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_tags = []\n",
    "\n",
    "for index in range(len(pol_data[\"Tagged Text\"])):\n",
    "    review_tags = []\n",
    "    for item in pol_data[\"Tagged Text\"][index]:\n",
    "        review_tags.append(item[1])\n",
    "    reviews_tags.append(review_tags)\n",
    "\n",
    "pol_data[\"POS Tags\"] = reviews_tags\n",
    "pol_data[\"POS Tags\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find ngram patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGrams(data, condition, value, pos_tags):\n",
    "    five_grams = []\n",
    "    six_grams = []\n",
    "    seven_grams = []\n",
    "\n",
    "    for index in range(len(pos_tags)):\n",
    "        if data[condition][index] == value:\n",
    "            # Six Grams\n",
    "            review_six_grams = list(ngrams(pos_tags[index], 6))\n",
    "            six_grams.append(review_six_grams)\n",
    "\n",
    "            # Five Grams\n",
    "            review_five_grams = list(ngrams(pos_tags[index], 5))\n",
    "            five_grams.append(review_five_grams)\n",
    "\n",
    "            # Seven Grams\n",
    "            review_seven_grams = list(ngrams(pos_tags[index], 7))\n",
    "            seven_grams.append(review_seven_grams)\n",
    "\n",
    "    flat_five_grams = [item for sublist in five_grams for item in sublist]\n",
    "    flat_six_grams = [item for sublist in six_grams for item in sublist]\n",
    "    flat_seven_grams = [item for sublist in seven_grams for item in sublist]\n",
    "\n",
    "    unsorted_polarity_grams = list(itertools.chain(flat_five_grams, flat_six_grams, flat_seven_grams))\n",
    "    \n",
    "    return unsorted_polarity_grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pattern Recognition for polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "unsorted_neutral_grams = getGrams(pol_data, \"Polarity\", \"neutral\", pol_data[\"POS Tags\"])\n",
    "neutral_grams = set(unsorted_neutral_grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "unsorted_negative_grams = getGrams(pol_data, \"Polarity\", \"negative\", pol_data[\"POS Tags\"])\n",
    "negative_grams = set(unsorted_negative_grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('VB', 'VBN', 'JJR', 'JJ', 'NN'), 23),\n",
       " (('MD', 'VB', 'VBN', 'JJR', 'JJ', 'NN'), 22),\n",
       " (('DT', 'JJ', 'NN', 'MD', 'VB', 'JJR'), 18),\n",
       " (('JJ', 'IN', 'IN', 'PRP', 'VBD'), 17),\n",
       " (('NN', 'VBD', 'IN', 'EX', 'VBD'), 17)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_neutral = [x for x in unsorted_neutral_grams if x not in negative_grams]\n",
    "\n",
    "mc_unique_neutral = list(Counter(unique_neutral).most_common(5000))\n",
    "mc_unique_neutral.sort(key=lambda x:x[1], reverse=True)\n",
    "mc_unique_neutral[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('NN', 'CD', 'RB', 'CD', 'NNS'), 90),\n",
       " (('CD', 'RB', 'CD', 'NNS', 'TO'), 90),\n",
       " (('NN', 'CD', 'RB', 'CD', 'NNS', 'TO'), 90),\n",
       " (('CD', 'RB', 'CD', 'NNS', 'TO', 'VB'), 90),\n",
       " (('NN', 'CD', 'RB', 'CD', 'NNS', 'TO', 'VB'), 90)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_negative = [x for x in unsorted_negative_grams if x not in neutral_grams]\n",
    "\n",
    "mc_unique_negative = list(Counter(unique_negative).most_common(5000))\n",
    "mc_unique_negative.sort(key=lambda x:x[1], reverse=True)\n",
    "mc_unique_negative[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_patterns(most_common):\n",
    "    unique_patterns = []\n",
    "    for item in most_common:\n",
    "        unique_patterns.append(list(item[0]))\n",
    "    return unique_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "neutral_patterns = unique_patterns(mc_unique_neutral)\n",
    "negative_patterns = unique_patterns(mc_unique_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns_df = pd.DataFrame(\n",
    "    data = {\n",
    "        \"neutral_patterns\": neutral_patterns,\n",
    "        \"negative_patterns\": negative_patterns\n",
    "    }\n",
    ")\n",
    "\n",
    "patterns_df.to_csv('data/polarity_patterns.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pattern recognition for star rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize reviews for POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                       [buddhism, conversion, course]\n",
       "1    [much, respect, for, richard, shell, he, talks...\n",
       "2    [nothing, practical, just, talking, and, lots,...\n",
       "3    [i, enjoyed, the, videos, but, not, the, assig...\n",
       "4    [the, course, is, well, structured, with, enou...\n",
       "Name: Review Text, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize all reviews for pre-processing purposes\n",
    "stars_data[\"Review Text\"] = stars_data[\"Review Text\"].apply(word_tokenize)\n",
    "stars_data[\"Review Text\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tag Reviews with POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [(buddhism, NN), (conversion, NN), (course, NN)]\n",
       "1    [(much, JJ), (respect, NN), (for, IN), (richar...\n",
       "2    [(nothing, NN), (practical, JJ), (just, RB), (...\n",
       "3    [(i, NN), (enjoyed, VBD), (the, DT), (videos, ...\n",
       "4    [(the, DT), (course, NN), (is, VBZ), (well, RB...\n",
       "Name: Tagged Text, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stars_data[\"Tagged Text\"] = stars_data[\"Review Text\"].apply(pos_tag)\n",
    "stars_data[\"Tagged Text\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                         [NN, NN, NN]\n",
       "1    [JJ, NN, IN, NN, NN, PRP, VBZ, CC, VBZ, PRP, P...\n",
       "2                  [NN, JJ, RB, VBG, CC, NNS, IN, VBG]\n",
       "3    [NN, VBD, DT, NNS, CC, RB, DT, NNS, RB, VBD, T...\n",
       "4    [DT, NN, VBZ, RB, VBN, IN, JJ, NN, VBN, IN, DT...\n",
       "Name: POS Tags, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_tags = []\n",
    "\n",
    "for index in range(len(stars_data[\"Tagged Text\"])):\n",
    "    review_tags = []\n",
    "    for item in stars_data[\"Tagged Text\"][index]:\n",
    "        review_tags.append(item[1])\n",
    "    reviews_tags.append(review_tags)\n",
    "\n",
    "stars_data[\"POS Tags\"] = reviews_tags\n",
    "stars_data[\"POS Tags\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "unsorted_onestar_grams = getGrams(stars_data, \"Stars\", 1, stars_data[\"POS Tags\"])\n",
    "onestar_grams = set(unsorted_onestar_grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "unsorted_twostar_grams = getGrams(stars_data, \"Stars\", 2, stars_data[\"POS Tags\"])\n",
    "twostar_grams = set(unsorted_twostar_grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "unsorted_threestar_grams = getGrams(stars_data, \"Stars\", 3, stars_data[\"POS Tags\"])\n",
    "threestar_grams = set(unsorted_threestar_grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "unsorted_fourstar_grams = getGrams(stars_data, \"Stars\", 4, stars_data[\"POS Tags\"])\n",
    "fourstar_grams = set(unsorted_fourstar_grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "unsorted_fivestar_grams = getGrams(stars_data, \"Stars\", 5, stars_data[\"POS Tags\"])\n",
    "fivestar_grams = set(unsorted_fivestar_grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('NN', 'CD', 'RB', 'CD', 'NNS'), 99),\n",
       " (('CD', 'RB', 'CD', 'NNS', 'TO'), 99),\n",
       " (('NN', 'CD', 'RB', 'CD', 'NNS', 'TO'), 99),\n",
       " (('CD', 'RB', 'CD', 'NNS', 'TO', 'VB'), 99),\n",
       " (('NN', 'CD', 'RB', 'CD', 'NNS', 'TO', 'VB'), 99)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_onestar = [x for x in unsorted_onestar_grams if x not in twostar_grams]\n",
    "\n",
    "mc_unique_onestar = list(Counter(unique_onestar).most_common(2000))\n",
    "mc_unique_onestar.sort(key=lambda x:x[1], reverse=True)\n",
    "mc_unique_onestar[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('CD', 'CD', 'CD', 'CD', 'CD'), 24),\n",
       " (('CD', 'CD', 'CD', 'CD', 'CD', 'CD'), 21),\n",
       " (('CD', 'CD', 'CD', 'CD', 'CD', 'CD', 'CD'), 18),\n",
       " (('VB', 'NN', 'RB', 'RB', 'IN'), 14),\n",
       " (('VBD', 'VBN', 'RB', 'IN', 'PRP'), 13)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_twostar = [x for x in unsorted_twostar_grams if x not in onestar_grams and x not in threestar_grams]\n",
    "\n",
    "mc_unique_twostar = list(Counter(unique_twostar).most_common(2000))\n",
    "mc_unique_twostar.sort(key=lambda x:x[1], reverse=True)\n",
    "mc_unique_twostar[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('JJ', 'NN', 'IN', 'VBN', 'TO'), 9),\n",
       " (('NN', 'MD', 'VB', 'NNS', 'VB'), 8),\n",
       " (('VBP', 'NN', 'CC', 'DT', 'NN'), 8),\n",
       " (('NN', 'NNS', 'CC', 'VBP', 'TO'), 8),\n",
       " (('NN', 'RB', 'IN', 'PRP', 'PRP'), 8)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_threestar = [x for x in unsorted_threestar_grams if x not in twostar_grams and x not in fourstar_grams]\n",
    "\n",
    "mc_unique_threestar = list(Counter(unique_threestar).most_common(2000))\n",
    "mc_unique_threestar.sort(key=lambda x:x[1], reverse=True)\n",
    "mc_unique_threestar[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('VB', 'DT', 'NN', 'DT', 'CD'), 9),\n",
       " (('TO', 'VB', 'DT', 'NNS', 'PRP', 'VBP'), 9),\n",
       " (('VB', 'JJ', 'TO', 'VB', 'JJR', 'NNS'), 9),\n",
       " (('NNS', 'RB', 'VBP', 'RB', 'VBN'), 7),\n",
       " (('PRP', 'CD', 'NNS', 'RB', 'IN'), 7)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_fourstar = [x for x in unsorted_fourstar_grams if x not in threestar_grams and x not in fivestar_grams]\n",
    "\n",
    "mc_unique_fourstar = list(Counter(unique_fourstar).most_common(2000))\n",
    "mc_unique_fourstar.sort(key=lambda x:x[1], reverse=True)\n",
    "mc_unique_fourstar[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('FW', 'FW', 'FW', 'FW', 'FW', 'FW', 'FW'), 24),\n",
       " (('NNP', 'NNP', 'NNP', 'NNP', 'NNP'), 19),\n",
       " (('VBD', 'CD', 'IN', 'DT', 'JJS'), 18),\n",
       " (('JJ', 'NN', 'NN', 'PRP', 'TO'), 17),\n",
       " (('NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP'), 16)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_fivestar = [x for x in unsorted_fivestar_grams if x not in fourstar_grams]\n",
    "\n",
    "mc_unique_fivestar = list(Counter(unique_fivestar).most_common(2000))\n",
    "mc_unique_fivestar.sort(key=lambda x:x[1], reverse=True)\n",
    "mc_unique_fivestar[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "onestar_patterns = unique_patterns(mc_unique_onestar)\n",
    "twostar_patterns = unique_patterns(mc_unique_twostar)\n",
    "threestar_patterns = unique_patterns(mc_unique_threestar)\n",
    "fourstar_patterns = unique_patterns(mc_unique_fourstar)\n",
    "fivestar_patterns = unique_patterns(mc_unique_fivestar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_patterns_df = pd.DataFrame(\n",
    "    data = {\n",
    "        \"onestar_patterns\": onestar_patterns,\n",
    "        \"twostar_patterns\": twostar_patterns,\n",
    "        \"threestar_patterns\": threestar_patterns,\n",
    "        \"fourstar_patterns\": fourstar_patterns,\n",
    "        \"fivestar_patterns\": fivestar_patterns,\n",
    "    }\n",
    ")\n",
    "\n",
    "star_patterns_df.to_csv('data/star_patterns.csv', index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1e4d29a3b69ac56eca58f5d61a6b46285dbd379c871590cc08b260a097abd0ce"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
